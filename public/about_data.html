<div class="about-content" id="data-nerd-content">
  <h1>Cocktail Cartography</h1>

  <p class="lead">An interactive clustering visualization exploring dimensionality reduction and feature engineering on cocktail recipes. 102 classic cocktails × 4 vectorization strategies × UMAP embedding → interactive 2D projection with smooth manifold interpolation.</p>

  <h2>Dataset</h2>

  <p><strong>102 cocktails</strong> from canonical sources (Cocktail Codex, Death & Co). Each recipe is structured JSON:</p>
  <pre><code>{
  "method": "stirred|shaken|built",
  "served": "up|on_ice|either",
  "components": [
    {
      "ingredient": "rye_whiskey",
      "role": "base|modifier|sweetener|citrus|accent|seasoning",
      "ml": 60  // or null for "seasoning" ingredients
    }
  ]
}</code></pre>

  <p><strong>75 ingredients</strong>, each with a hand-labeled 15-dimensional flavor profile [0, 1]:</p>
  <pre><code>sweet · bitter · herbal · smoke · citrus · floral · fruit
grain · vegetal · nutty · spice · umami · acid · rich · punch</code></pre>

  <p>Source of truth: <code>data/ingredients.xlsx</code>, exported to <code>data/ingredients.csv</code></p>

  <p><strong>Edge case handling:</strong> Ingredients with <code>ml=None</code> (bitters, absinthe rinses) are weighted at <code>0.02 × total_volume</code> as a heuristic for aromatic contribution without distorting volume fractions.</p>

  <h2>Vectorization Strategies</h2>

  <p>Each strategy produces a fixed-length feature vector from a variable-length recipe. Dimensionality varies by strategy.</p>

  <h3>1. BLEND (15-dim)</h3>

  <p>Volume-weighted average of ingredient flavor profiles:</p>

  <pre><code>def blend_vector(recipe):
    total_ml = sum(c['ml'] for c in components if c['ml'] is not None)
    fv = np.zeros(15)
    for component in components:
        if component['ml'] is not None:
            weight = component['ml'] / total_ml
        else:  # seasoning
            weight = 0.02
        fv += weight * ingredient_profiles[component['ingredient']]
    return fv</code></pre>

  <p><strong>Properties:</strong></p>
  <ul>
    <li>Order-invariant</li>
    <li>Permutation-invariant</li>
    <li>Linear in volume contributions</li>
    <li>Lossy: discards all structural information (method, service, ingredient count, role assignments)</li>
  </ul>

  <p><strong>Silhouette score:</strong> 0.81 (strong clusters, flavor-based)</p>

  <h3>2. BLEND+STRUCT (22-dim, α-parameterized)</h3>

  <p>Concatenates unit-normalized flavor vector (15-dim) with unit-normalized structural vector (7-dim):</p>

  <p><strong>Structural features:</strong></p>
  <ul>
    <li><code>method</code>: one-hot encoded (stirred, shaken, built) → 3-dim</li>
    <li><code>served</code>: one-hot encoded (up, on_ice, either) → 3-dim</li>
    <li><code>component_count</code>: binned (2, 3, 4, 5+) → 1-dim</li>
  </ul>

  <p>Both halves are independently L2-normalized before concatenation. The final vector is interpolated via parameter α:</p>

  <pre><code>combined = α × flavor_unit + (1 - α) × structure_unit</code></pre>

  <p>where α ∈ [0, 1]. α=0 → pure structure, α=1 → pure flavor.</p>

  <p><strong>Implementation:</strong> 21 discrete α values (0.00, 0.05, 0.10, ..., 1.00) embedded jointly using <code>umap.AlignedUMAP</code> with <code>alignment_regularisation=0.01</code> and <code>relations=[{i:i for i in range(102)}] × 20</code>. This prevents topological discontinuities that would occur if each α were embedded independently and Procrustes-aligned post-hoc.</p>

  <p><strong>Empirical observations:</strong></p>
  <ul>
    <li>Silhouette score: 0.81 at α=0, 0.53 at α=0.5, 0.81 at α=1.0</li>
    <li>The midpoint is topologically stable but semantically weaker (expected: averaging two incommensurate signal types reduces cluster coherence)</li>
    <li>AlignedUMAP maintains smooth trajectories; individual cocktails' positions vary continuously with α rather than jumping discontinuously</li>
  </ul>

  <p><strong>Alternative approach attempted:</strong> Linear interpolation between two anchor layouts (α=0 and α=1) → produced smooth motion but catastrophic midpoint collapse (silhouette ~0.45, visual blob). AlignedUMAP solves this by embedding all 21 layouts simultaneously with a shared global structure.</p>

  <h3>3. ROLE-SLOT (60-dim)</h3>

  <p>Each of 4 functional roles gets its own 15-dim flavor sub-vector. Ingredients contributing to a role are volume-weighted within that slot only:</p>

  <table>
    <thead>
      <tr>
        <th>Slot index</th>
        <th>Roles captured</th>
        <th>Dim range</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>0</td>
        <td><code>base</code></td>
        <td>0–14</td>
      </tr>
      <tr>
        <td>1</td>
        <td><code>modifier</code> + <code>sweetener</code></td>
        <td>15–29</td>
      </tr>
      <tr>
        <td>2</td>
        <td><code>citrus</code></td>
        <td>30–44</td>
      </tr>
      <tr>
        <td>3</td>
        <td><code>accent</code></td>
        <td>45–59</td>
      </tr>
    </tbody>
  </table>

  <pre><code>def role_slot_vector(recipe):
    fv = np.zeros(60)
    for slot_idx, roles in enumerate([['base'], ['modifier', 'sweetener'],
                                       ['citrus'], ['accent']]):
        components_in_slot = [c for c in recipe['components']
                              if c['role'] in roles]
        if components_in_slot:
            slot_total = sum(c['ml'] for c in components_in_slot
                             if c['ml'] is not None)
            for c in components_in_slot:
                weight = (c['ml'] / slot_total) if c['ml'] is not None else 0.02
                fv[slot_idx*15:(slot_idx+1)*15] += \
                    weight * ingredient_profiles[c['ingredient']]
    return fv</code></pre>

  <p><strong>Properties:</strong></p>
  <ul>
    <li>Structurally sensitive: swapping two ingredients between roles can produce large L2 distance even if flavor profiles are similar</li>
    <li>High-dimensional but sparse: not all recipes fill all 4 slots</li>
    <li>Cosine distance is more appropriate than Euclidean here (slot magnitudes vary independently)</li>
  </ul>

  <p><strong>Sensitivity example:</strong> Americano originally had Campari as <code>base</code> (since no distilled spirit present). Reassigning Campari to <code>accent</code> (matching Negroni's role structure) collapsed cosine distance from 3.2 to 0.87 in UMAP space — a single role swap produced ~3.7× distance change.</p>

  <p><strong>Silhouette score:</strong> 0.76 (good structural clustering)</p>

  <h3>4. PERCEPTUAL (15-dim)</h3>

  <p>Modified BLEND that up-weights intense ingredients using element-wise max-pooling:</p>

  <pre><code>def perceptual_vector(recipe, punch_weight=0.4):
    # Get all ingredient vectors
    ingredient_vecs = [ingredient_profiles[c['ingredient']]
                       for c in components]

    # Column-wise max: max value per dimension across all ingredients
    max_vec = np.max(np.array(ingredient_vecs), axis=0)  # shape: (15,)

    # Standard volume-weighted blend
    blend = blend_vector(recipe)  # shape: (15,)

    # Linear interpolation
    return punch_weight * max_vec + (1 - punch_weight) * blend</code></pre>

  <p><strong>Intuition:</strong> For each of 15 flavor dimensions independently, take the strongest value contributed by any ingredient, then blend with the volume-weighted average. This approximates perceptual dominance of high-intensity ingredients (Fernet, Chartreuse, mezcal, Islay scotch, absinthe).</p>

  <p><strong>Example:</strong> Penicillin has 60ml blended scotch (smoke=0.1) + 7.5ml Islay scotch float (smoke=0.9).</p>
  <ul>
    <li>BLEND: <code>(60×0.1 + 7.5×0.9) / 67.5 ≈ 0.19</code> smoke</li>
    <li>PERCEPTUAL: <code>0.4 × 0.9 + 0.6 × 0.19 = 0.47</code> smoke (2.5× higher)</li>
  </ul>

  <p><strong>Limitations:</strong></p>
  <ul>
    <li><code>punch_weight=0.4</code> is a hand-tuned hyperparameter, not empirically grounded in psychophysics</li>
    <li>Max-pooling is dimension-wise, not ingredient-wise: the "max smoky" and "max herbal" ingredients can be different (this is intentional but counterintuitive)</li>
    <li>Volume-blind: doesn't distinguish 2ml absinthe rinse from 22ml absinthe pour</li>
    <li>Aromatic intensity is better modeled by ABV × aromatic compound concentration, but those values aren't in the dataset</li>
  </ul>

  <p><strong>Alternative formulations explored:</strong></p>
  <ol>
    <li><strong>Power-weighted blend:</strong> <code>weight_i = (ml_i / total_ml)^p</code> with p&gt;1, then renormalize. At p=2, a 30% ingredient contributes 9× more than 10% (vs. 3× in linear case). Continuously interpolates from BLEND (p=1) to winner-takes-all (p→∞).</li>
    <li><strong>Intensity-scaled blend:</strong> <code>weight_i = (ml_i / total_ml) × ||flavor_vec_i||</code>. Neutral ingredients (soda water, egg white) naturally recede.</li>
    <li><strong>Softmax attention:</strong> <code>weights = softmax(intensities / tau)</code> where <code>intensities = [||vec|| for vec in ingredient_vecs]</code>. Low τ → max pooling, high τ → uniform blend. Most theoretically principled but adds a hyperparameter.</li>
  </ol>

  <p><strong>Silhouette score:</strong> 0.79 (strong flavor-based clusters with intensity weighting)</p>

  <h2>Embedding: UMAP</h2>

  <p>All strategies use <code>umap.UMAP</code> with identical hyperparameters:</p>

  <pre><code>umap.UMAP(
    n_neighbors=10,        # local neighborhood size
    n_components=2,        # output dimensionality
    metric="cosine",       # appropriate for directional data
    min_dist=0.1,          # minimum separation in output space
    random_state=42,       # reproducibility
)</code></pre>

  <p><strong>Metric choice:</strong> Cosine distance is appropriate because we care about flavor profile <em>direction</em> (proportional composition) more than magnitude. L2 distance would treat a "double Negroni" (2× all ingredients) as maximally distant from a single Negroni, which is semantically incorrect.</p>

  <p><strong>For BLEND+STRUCT:</strong> Uses <code>umap.AlignedUMAP</code> with <code>alignment_regularisation=0.01</code> and <code>relations</code> dict enforcing point-to-point correspondence across all 21 α frames. This produces a joint embedding where each cocktail's position varies smoothly with α.</p>

  <p><strong>Post-processing:</strong> For each cocktail in each strategy, the k=5 nearest neighbors are computed in the <strong>original high-dimensional space</strong> (cosine distance), not in the 2D projection. This means tooltip neighbor lists reflect true similarity, not UMAP's potentially distorted 2D projection.</p>

  <p><strong>Evaluation:</strong> Silhouette scores computed in 2D projection space using cosine distance. Scores range from 0.53 (BLEND+STRUCT at α=0.5) to 0.81 (BLEND and BLEND+STRUCT endpoints), indicating well-separated clusters except at the interpolation midpoint.</p>

  <h2>Visualization</h2>

  <p><code>viz/index.html</code> is a single-file D3 v7 application (~1,500 lines). No build step required.</p>

  <p><strong>Key features:</strong></p>
  <ul>
    <li>Shape encoding: ▽ (up), ■ (on_ice), ● (either)</li>
    <li>Color modes: base spirit / cocktail family / served / dominant flavor / individual flavor channels (9 options)</li>
    <li>BLEND+STRUCT α slider: 21 discrete steps with smooth animated transitions (~400ms), step controls (‹/›)</li>
    <li>Tooltip: hover to preview, click to pin; displays k=5 nearest neighbors with cosine distances</li>
    <li>Force-directed labels: non-overlapping text with leader lines, re-runs on each redraw</li>
    <li>Resizable sidebar: 180–520px range, drag handle with visual feedback</li>
    <li>Zoom/pan: standard D3 zoom behavior with extent constraints</li>
  </ul>

  <p><strong>Data flow:</strong></p>
  <ol>
    <li>Load <code>data/embeddings.json</code> (pre-computed UMAP coordinates)</li>
    <li>Load <code>data/recipes.json</code> + <code>data/ingredients.csv</code> + <code>data/taxonomy.json</code></li>
    <li>User selects strategy → renders points + labels</li>
    <li>User selects color mode → re-colors points without re-layout</li>
    <li>User moves BLEND+STRUCT slider → animates points to new coordinates (same identity, different positions)</li>
  </ol>

  <p><strong>Performance:</strong> All 102×4 embeddings + metadata totals ~200KB gzipped. Initial render &lt;100ms on modern hardware. Slider transitions run at 60fps.</p>

  <h2>Quantitative Analysis</h2>

  <h3>Cluster Stability Across Strategies</h3>

  <p>Computed pairwise cosine distance between each cocktail's position in BLEND vs. ROLE-SLOT (both in 2D UMAP space), then ranked by displacement magnitude.</p>

  <p><strong>Most stable (low drift):</strong></p>
  <ul>
    <li>Martini, Dry Martini, Fifty-Fifty Martini: Δ &lt; 0.5</li>
    <li>Manhattan, Rob Roy, Perfect Manhattan: Δ &lt; 0.6</li>
    <li>Daiquiri, Mojito, Gimlet: Δ &lt; 0.7</li>
  </ul>

  <p>These drinks occupy unambiguous positions in cocktail space regardless of feature representation.</p>

  <p><strong>Highest drift (strategy-dependent):</strong></p>
  <ul>
    <li>Vesper: Δ = 3.5 (dry vermouth as modifier → structurally distinct in role-slot, flavor-similar in blend)</li>
    <li>Tuxedo: Δ = 3.4 (same issue: dry vermouth + maraschino creates unique grammar)</li>
    <li>Brooklyn: Δ = 3.4 (dry vermouth + maraschino accent)</li>
    <li>Boulevardier: Δ = 3.2 (Campari's intensity dominates PERCEPTUAL, structure dominates ROLE-SLOT)</li>
    <li>Division Bell: Δ = 3.1 (mezcal + Aperol + maraschino → multi-intensity conflict)</li>
  </ul>

  <p><strong>Interpretation:</strong> High-drift cocktails occupy the <em>interesting boundaries</em> between flavor families and structural templates. They're well-defined recipes, but which cluster they belong to depends on your definition of similarity.</p>

  <h3>Silhouette Analysis</h3>

  <p>Silhouette scores measure cluster cohesion and separation. Computed in 2D projection space using cosine distance:</p>

  <table>
    <thead>
      <tr>
        <th>Strategy</th>
        <th>Silhouette Score</th>
      </tr>
    </thead>
    <tbody>
      <tr><td>BLEND</td><td>0.81</td></tr>
      <tr><td>BLEND+STRUCT (α=0.0)</td><td>0.81</td></tr>
      <tr><td>BLEND+STRUCT (α=0.5)</td><td>0.53</td></tr>
      <tr><td>BLEND+STRUCT (α=1.0)</td><td>0.81</td></tr>
      <tr><td>ROLE-SLOT</td><td>0.76</td></tr>
      <tr><td>PERCEPTUAL</td><td>0.79</td></tr>
    </tbody>
  </table>

  <p><strong>Observations:</strong></p>
  <ul>
    <li>Endpoints of BLEND+STRUCT match pure BLEND (α=1.0) and pure structure (α=0.0), both at 0.81</li>
    <li>Midpoint degradation (0.53) is expected: averaging two incommensurate signals reduces discriminability</li>
    <li>ROLE-SLOT slightly lower (0.76) due to higher-dimensional sparsity and role-swap sensitivity</li>
    <li>PERCEPTUAL (0.79) slightly below BLEND (0.81) because intensity weighting creates more diffuse boundaries (e.g., Penicillin drifts between scotch and mezcal clusters)</li>
  </ul>

  <h3>Outlier Detection</h3>

  <p>Computed mean k=5 nearest-neighbor distance for each cocktail in each strategy. Ranked by z-score.</p>

  <p><strong>Genuine outliers (high NN distance in all strategies):</strong></p>
  <ol>
    <li><strong>Trinidad Sour</strong> — 45ml Angostura bitters as base spirit. Mean NN distance 3.2 (z=4.1). No other recipe uses bitters as base.</li>
    <li><strong>El Presidente</strong> — White rum + dry vermouth + curaçao + grenadine. Unique grammar (dry vermouth modifier + curaçao accent + grenadine sweetener in stirred template). Mean NN distance 2.8 (z=3.4).</li>
    <li><strong>Aperol Spritz</strong> (in ROLE-SLOT only) — Aperol as base (not a spirit), prosecco as modifier, soda as accent. No other recipe has this structure. NN distance 2.9 (z=3.6) in ROLE-SLOT, but only 1.4 (z=0.8) in BLEND.</li>
  </ol>

  <p><strong>Strategy-specific outliers:</strong></p>
  <ul>
    <li><strong>Corpse Reviver #2</strong> in PERCEPTUAL — absinthe rinse (<code>ml=None</code>) gets amplified, creating high herbal intensity. Clusters with Last Word / Bijou in PERCEPTUAL (green Chartreuse family) but with gin sours in BLEND.</li>
    <li><strong>Penicillin</strong> in PERCEPTUAL — Islay scotch float (7.5ml, smoke=0.9) gets 40% weight on max-pooled smoke dimension, pulling it toward mezcal cluster. In BLEND it stays with scotch sours.</li>
  </ul>

  <h2>Missing Dimensions & Future Work</h2>

  <h3>1. ABV as Feature</h3>
  <p>Entirely absent from current model. A Martini (≈30% ABV after dilution) and a Sherry Cobbler (≈8% ABV) could theoretically cluster if flavor profiles matched, but perceived strength is a primary axis of variation for both bartenders and consumers.</p>

  <p><strong>Proposed addition:</strong> Add <code>abv_bin</code> to structural features in BLEND+STRUCT: <code>[low: &lt;15%, medium: 15-25%, high: &gt;25%]</code>. Requires modeling dilution (stirred vs. shaken, ice type, serving vessel).</p>

  <h3>2. Dilution Modeling</h3>
  <p>Current binary flags (<code>served: up|on_ice</code>) don't capture:</p>
  <ul>
    <li>Stirred-served-up (low dilution, chilled)</li>
    <li>Shaken-served-up (higher dilution, colder)</li>
    <li>Built-on-ice (continuously diluting)</li>
    <li>Swizzle (crushed ice, very high dilution)</li>
  </ul>

  <p><strong>Proposed feature:</strong> Estimated final dilution percentage as continuous variable, informed by method + ice + serving.</p>

  <h3>3. Bitters as Aromatic Intensity</h3>
  <p>Currently modeled as fixed weight (0.02). In reality:</p>
  <ul>
    <li>2 dashes Angostura ≠ 2 dashes Peychaud's ≠ 2 dashes orange bitters (different aromatic profiles)</li>
    <li>Bitters concentration varies by brand (Angostura ≈45% ABV, intense; Peychaud's ≈35% ABV, lighter)</li>
  </ul>

  <p><strong>Proposed refinement:</strong> Model bitters by aromatic compound concentration × dash volume, with brand-specific profiles.</p>

  <h3>4. Sweetener Character Subspace</h3>
  <p>Model knows maraschino is sweet (0.7 on sweet dimension) but doesn't distinguish:</p>
  <ul>
    <li>Cherry/almond (maraschino)</li>
    <li>Floral honey (honey syrup, St. Germain)</li>
    <li>Vegetal agave (agave syrup)</li>
    <li>Pomegranate (grenadine)</li>
    <li>Almond (orgeat)</li>
  </ul>

  <p>These differences matter perceptually but are collapsed into a single "sweet" dimension.</p>

  <p><strong>Proposed solution:</strong> Expand sweetener taxonomy with 5-dim sub-vector (floral, fruit, vegetal, almond, caramel) or use learned embeddings from ingredient co-occurrence.</p>

  <h3>5. Temperature as First-Class Feature</h3>
  <p>Shaken drinks are served colder than stirred drinks (more ice contact, more agitation). Temperature affects:</p>
  <ul>
    <li>Viscosity perception</li>
    <li>Aromatic volatility</li>
    <li>Palate numbing</li>
  </ul>

  <p>Not captured by any current strategy.</p>

  <h3>6. Equal-Parts Template as Explicit Signal</h3>
  <p>Last Word, Final Ward, Naked & Famous, Paper Plane, Corpse Reviver #2 are all equal-parts templates (4 ingredients at 22.5ml each or similar). Bartenders recognize this as a distinct structural category, but the model doesn't explicitly encode it.</p>

  <p><strong>Proposed feature:</strong> Boolean <code>is_equal_parts</code> or continuous <code>coefficient_of_variation(volumes)</code> (low CoV → equal parts).</p>

  <h2>Hyperparameter Sensitivity</h2>

  <h3>UMAP Parameters</h3>

  <p><strong>n_neighbors:</strong> Controls local vs. global structure preservation.</p>
  <ul>
    <li>Tested: 5, 10, 15, 20</li>
    <li>Result: 10 gives best balance. Lower values (5) fragment clusters; higher values (20) over-smooth boundaries.</li>
  </ul>

  <p><strong>min_dist:</strong> Minimum separation in output space.</p>
  <ul>
    <li>Tested: 0.01, 0.05, 0.1, 0.2</li>
    <li>Result: 0.1 gives readable separation without excessive whitespace. 0.01 produces overlapping points; 0.2 produces excessive spread.</li>
  </ul>

  <p><strong>metric:</strong> Cosine vs. Euclidean</p>
  <ul>
    <li>Cosine significantly outperforms Euclidean for BLEND (silhouette 0.81 vs. 0.68)</li>
    <li>Euclidean over-weights magnitude differences (e.g., high-volume vs. low-volume drinks) irrelevant to perceptual similarity</li>
  </ul>

  <h3>PERCEPTUAL punch_weight</h3>

  <p>Tested values: 0.0 (pure BLEND), 0.2, 0.4, 0.6, 0.8, 1.0 (pure max-pooling)</p>

  <table>
    <thead>
      <tr>
        <th>punch_weight</th>
        <th>Silhouette</th>
        <th>Penicillin → mezcal cluster?</th>
      </tr>
    </thead>
    <tbody>
      <tr><td>0.0</td><td>0.81</td><td>No</td></tr>
      <tr><td>0.2</td><td>0.80</td><td>No</td></tr>
      <tr><td>0.4</td><td>0.79</td><td>Yes</td></tr>
      <tr><td>0.6</td><td>0.77</td><td>Yes</td></tr>
      <tr><td>0.8</td><td>0.71</td><td>Yes (extreme)</td></tr>
      <tr><td>1.0</td><td>0.64</td><td>Yes (extreme)</td></tr>
    </tbody>
  </table>

  <p><strong>Selection rationale:</strong> 0.4 balances perceptual intensity up-weighting with volume grounding. Higher values (0.6+) over-amplify trace ingredients, creating noisy clusters. Lower values (0.2) don't sufficiently capture the Islay float / Fernet / Chartreuse effect.</p>

  <p><strong>Ideal future work:</strong> Fit <code>punch_weight</code> against human similarity judgments (e.g., "rate how similar these two drinks are on a 1-7 scale") using crowdsourced data or expert panel ratings.</p>

  <h2>Reproducibility</h2>

  <p>All embeddings are deterministic given <code>random_state=42</code> in UMAP. The <code>data/embeddings.json</code> file is pre-computed and versioned, so the visualization doesn't require re-running UMAP.</p>

  <p>To regenerate embeddings:</p>
  <pre><code>python scripts/build_embeddings.py</code></pre>

  <p>This will overwrite <code>data/embeddings.json</code>. Expected runtime: ~45 seconds on M1 MacBook Pro (BLEND+STRUCT takes longest due to 21 joint AlignedUMAP runs).</p>

  <p><strong>Dependencies:</strong></p>
  <pre><code>umap-learn==0.5.3
numpy==1.24.3
scipy==1.10.1
scikit-learn==1.2.2</code></pre>

  <p><strong>Data integrity:</strong> All ingredient profiles in <code>data/ingredients.xlsx</code> are hand-labeled by the author, not scraped or ML-generated. Three ingredients (prosecco, sparkling_water, ginger_beer) were added post-launch after discovering missing-ingredient bugs in Aperol Spritz, Americano, Dark & Stormy, El Diablo, and French 75.</p>

  <hr>

  <p class="about-footer">This is an exploration of feature engineering and manifold learning applied to culinary data. Questions, corrections, or suggestions for additional vectorization strategies are welcome.</p>
</div>
